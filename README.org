* Procedural Generation Experiments

#+html: <p align="center"><img src="media/screenshot.png" /></p>

** Philosophy
  - Highly interactive
  - Climbing the [[http://worrydream.com/LadderOfAbstraction/][ladder of abstraction]]

** Implemented
   - (Simple) L-systems
   - (Simple) Turtle interpretation
   - Static GUI to display parameters
   - Dynamic GUIs to interact with the parameters

** Main Roadmap
   1. Save and load L-system models
   2. Add a more complex GUI and polish it
      * Slider speed
      * Color-coded LSystems windows
      * Unique permanent ID to LSystemView to avoid window redefinition
      * Using `SetNextWindow*()` to a more pretty default
   3. Add genetic algorithm or constraint-based algorithm for new LSystem generation
   4. Make the generated vertices pretty (colors and growth) (example in dev.color and dev.time)

** Other ideas

** Next Bugs

** Optimization, non-urgent bugs and cleanup
   - Optimization
     With the current algorithm, execution time and memory consumption are exponential. Memory consumption is the biggest factor, as several GB can be allocated easily (from 16 iterations).
     - Cache multi-iteration production rules (*very good* for execution time (from O(x^n) to O(n)) but bad for memory consumption). Useful when calculating L-System productions but not for vertices computation, which is the biggest time hog.
     - Compute the vertices from the position (0,0) and use sf::RenderStates to define real position and angle: *huge* gain for the most common operation: moving around the vertices.
     - Use raw OpenGL vertices instead of SFML's sf::Vertex to reduce their size (no texcoord for example)
     - Use `sqrt` instead of `cos` and `sin` for angles to calculate vertex's position

   - Bugs
     - Correct floating point errors when using big number of iterations (using double)
     - Correct zoom level and drag behaviour when resizing window (in Gnome)

   - Cleanup
     - Make 'DrawingParameters' an Observable

** Development framework
   - *Environment:* debian sid chroot with these development packages: =g++ make git libsfml-dev googletest gdb valgrind=
   - *Dependencies:*
     - SFML / 2.4.1 / [[https://www.sfml-dev.org/][Website]] / installed from packages / 
     - googletest / 1.7.0 / [[https://github.com/google/googletest][Github Repository]] / installed from packages
     - dear imgui, / 1.5 / [[https://github.com/ocornut/imgui][Github Repository]] / installed via [[https://github.com/ocornut/imgui/releases/tag/v1.50][release 1.5]] / included in the repo
     - imgui-sfml / 2017-07-04 / [[https://github.com/eliasdaler/imgui-sfml][Github Repository]] / installed via the instructions from the README.org of the repository / included in the repo
     - GSL (Guidelines Support Library) / 2017-06-27 / [[https://github.com/Microsoft/GSL][Github Repository]] / cloned from the repository / included in the repo
     - cereal / 1.2.2 / [[https://uscilab.github.io/cereal/index.html][Website]] / downloaded from the website / included in the repo
   - *Coding rule:* [[https://github.com/isocpp/CppCoreGuidelines][ISO C++ Core Guidelines]] with GSL
     - Difference: [[https://en.wikipedia.org/wiki/Indentation_style#Allman_style][Allman indentation Style]]
     - Difference: When using ImGui ; ImGui style of coding
   - *Compilation:* =make= and C++17 needed
   - *Testing suite:* [[https://github.com/google/googletest/][googletest]]

** Completing the framework?
   - Static analysis (Coverity?)
   - Formal documentation (Doxygen?)
   - Automatic cross-compiling?
   - Automatic on-screen serialization?

** Thoughts dump
  - Huge literature on the subject and extremely developed existing software. What does this project bring?
*** Memory allocation with Valgrind (2017-09-17 Epholys)
    =valgrind --tool\=massif --time-unit\=B --peak-inaccuracy=0.1=

    Memory usage is directly linked to the size of the L-Systems calculated. These sizes grow exponentialy, so does the memory. As an example, with a simple L-System and 16 iterations, the resulting string is composed of tens of million of symbols. Saving these symbols and the 20-bytes-long vertices associated takes at least hundreds of MB in memory.
    Moreover, during the execution of =logo::computes_vertices=, we use a =std::vector= as data structure. Its allocation strategy (in g++ and MSVC) is to multiply the capacity by a number. As a consequence, this vector is at most "factor" times too large. In our case of hundreds of MB, it can be a serious toll. Fortunately, this vector is truncated when returned by the function.
    
    I don't see an *obvious* way to reduce memory consumption. Symbols and vertices are already very small. We could reduce the size of the aforementioned vector by reserving just enough bytes for the vertices. But that means we would have to approximate a small upper-bound of the result of the L-System and also how much of its symbols will produce a new vertex. A whole mathematical problem.

    For now, I'll do nothing: I see no reasonable case to computes and display so much iterations of a L-System. I'll concentrate on optimizing execution time (with memory consumption in mind).

** (Res)sources
[[http://blog.rabidgremlin.com/2014/12/09/procedural-content-generation-l-systems/][Procedural content generation: L-Systems (by Rabidgremlin)]]

[[http://algorithmicbotany.org/papers/#abop][The Algorithmic Beauty of Plants]]

[[https://www.reddit.com/r/lsystem/][/r/lsystem]]

[[http://jobtalle.com/lindenmayer_systems.html][Job Talle -- Lindermayer systems]]
